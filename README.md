# Deep-Image-Decoding-From-Neural-Activity
Explaining and predicting behavior from neural activity has been a longstanding goal in neuroscience. It is known that visual information is encoded within the hierarchical structure of the visual cortex, and plays an essential role in visual processing. However, the decoding of stimulus images from neural activity is still a challenging topic. Here we ask whether neural activity in the visual cortex of mice can be used to decode stimulus images, and whether specific visual cortex subregions recreate the images better than others. We hypothesize that neurons in the primary visual cortex (VISp) would best recreate these images. To investigate this, we employed a decoding approach outlined in previous literature. We obtained image visual features from a pre-trained deep residual neural network (ResNet), and created a linear mapping to corresponding neural activity (spike counts). This was then used to reconstruct the stimulus images through a generative adversarial network (GAN)-type layer. We observed that our model successfully decoded stimulus images from neural activity. In addition, we found that VISp neurons achieve greater decoding quality relative to other subregions. We conclude that our model can be used to accurately reconstruct stimulus images from neuronal spike counts, and that neuronal activity in the VISp encoded the majority of the information. Our findings may inspire a simple yet effective architecture for novel brain-computer-interface applications. Since our dataset contained a limited number of images and neuronal responses from one subject, generalization may be limited. We also have not examined whether combinations of subregions can recreate images better than single 
